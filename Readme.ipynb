{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288fb5e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 🌐 **AI AVENGERS PROMPT MAP — TIME SERIES REVENUE FORECASTING PROJECT**\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 **STEP 1 — PROJECT BLUEPRINT (Claude)**\n",
    "**Goal:** Create the folder structure, Makefile, and README.  \n",
    "\n",
    "**Prompt for Claude:**\n",
    "```\n",
    "Create a complete folder structure, README, and Makefile for a project titled\n",
    "“Future Revenue Forecasting using Historical and Textual Data (FDE Project)”.\n",
    "\n",
    "Project Description:\n",
    "A Python-based machine learning project that forecasts future monthly revenue using\n",
    "historical financial data and textual line-item descriptions.\n",
    "Uses NLP, clustering, XGBoost, and time series forecasting to improve accuracy.\n",
    "\n",
    "Deliverables:\n",
    "• revenue_forecast_model.pkl\n",
    "• preprocessing_pipeline.pkl\n",
    "• model_metrics.json\n",
    "• feature_importance.png\n",
    "• cluster_analysis.csv\n",
    "• monthly_forecasts.csv\n",
    "• retrain_script.py\n",
    "\n",
    "Include these directories:\n",
    "- data/raw, data/processed\n",
    "- src (with modules: preprocess.py, feature_engineering.py, clustering.py, model_training.py, time_series_model.py, evaluate.py, retrain_script.py, dashboard/app.py)\n",
    "- models/\n",
    "- reports/\n",
    "- requirements.txt\n",
    "- README.md\n",
    "\n",
    "Makefile commands:\n",
    "- make preprocess\n",
    "- make train\n",
    "- make evaluate\n",
    "- make retrain\n",
    "- make dashboard\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **STEP 2 — DATA GENERATION (Gemini)**\n",
    "**Goal:** Generate synthetic 24-month dataset with textual line items.  \n",
    "\n",
    "**Prompt for Gemini:**\n",
    "```\n",
    "Generate a synthetic dataset named revenue_data.csv with 24 months of data (Jan 2024 – Dec 2025).\n",
    "Include around 300–500 rows.\n",
    "\n",
    "Columns:\n",
    "- month (YYYY-MM)\n",
    "- region (North, South, East, West)\n",
    "- product_category (Software, Hardware, Services)\n",
    "- line_item_description (short invoice-like text)\n",
    "- revenue (float between 10,000–200,000)\n",
    "\n",
    "Ensure realistic variation and save as CSV.\n",
    "Show first 10 rows of the dataset preview.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **STEP 3 — PREPROCESSING & NLP PIPELINE (ChatGPT)**\n",
    "**Goal:** Clean and transform data, handle text and categorical features.  \n",
    "\n",
    "**Prompt for ChatGPT:**\n",
    "```\n",
    "Generate src/preprocess.py for the FDE Revenue Forecasting Project.\n",
    "\n",
    "Steps:\n",
    "1. Load revenue_data.csv\n",
    "2. Handle missing values\n",
    "3. Encode categorical variables (region, product_category)\n",
    "4. Tokenize 'line_item_description' using NLTK\n",
    "5. Remove stopwords, apply TF-IDF vectorization\n",
    "6. Combine structured + textual features\n",
    "7. Save preprocessing_pipeline.pkl and clean_data.csv\n",
    "\n",
    "Use sklearn.pipeline and joblib for saving.\n",
    "Ensure clean modular design and logging for each stage.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 **STEP 4 — CLUSTERING (ChatGPT)**\n",
    "**Goal:** Add cluster-based feature for interpretability.  \n",
    "\n",
    "**Prompt for ChatGPT:**\n",
    "```\n",
    "Generate src/clustering.py for the FDE project.\n",
    "\n",
    "Steps:\n",
    "1. Load clean_data.csv and TF-IDF matrix\n",
    "2. Apply KMeans clustering to the textual TF-IDF features\n",
    "3. Determine optimal clusters using Elbow Method (optional)\n",
    "4. Add 'cluster_label' column to dataset\n",
    "5. Save cluster_analysis.csv\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ **STEP 5 — MODEL TRAINING (ChatGPT)**\n",
    "**Goal:** Build and train XGBoost model.  \n",
    "\n",
    "**Prompt for ChatGPT:**\n",
    "```\n",
    "Generate src/model_training.py for the FDE Revenue Forecasting Project.\n",
    "\n",
    "Steps:\n",
    "1. Load processed data with cluster features\n",
    "2. Split into train/test (80/20)\n",
    "3. Train XGBoostRegressor\n",
    "4. Optimize hyperparameters using RandomizedSearchCV\n",
    "5. Evaluate using RMSE, MAE, and R²\n",
    "6. Save model_metrics.json\n",
    "7. Plot and save feature importance as feature_importance.png\n",
    "8. Save trained model as revenue_forecast_model.pkl\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ⏳ **STEP 6 — TIME SERIES FORECASTING (ChatGPT)**\n",
    "**Goal:** Forecast next 3 months using ARIMA or Prophet.  \n",
    "\n",
    "**Prompt for ChatGPT:**\n",
    "```\n",
    "Create src/time_series_model.py that trains a time series model for revenue forecasting.\n",
    "\n",
    "Steps:\n",
    "1. Aggregate revenue by month from clean_data.csv\n",
    "2. Use Prophet or ARIMA for forecasting\n",
    "3. Predict next 3 months revenue\n",
    "4. Plot historical + forecast data\n",
    "5. Save outputs as monthly_forecasts.csv and revenue_forecast_plot.png\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ **STEP 7 — AUTOMATED RETRAINING (ChatGPT)**\n",
    "**Goal:** Automate periodic model updates.  \n",
    "\n",
    "**Prompt for ChatGPT:**\n",
    "```\n",
    "Generate src/retrain_script.py that automates retraining for the FDE project.\n",
    "\n",
    "Functionality:\n",
    "- Load new monthly data\n",
    "- Update preprocessing and clustering\n",
    "- Retrain XGBoost + time series models\n",
    "- Save new models and metrics\n",
    "- Integrate with Makefile (make retrain)\n",
    "- Include logging and versioning of models\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 **STEP 8 — DASHBOARD INTEGRATION (Gemini or ChatGPT)**\n",
    "**Goal:** Interactive visualization and model insights.  \n",
    "\n",
    "**Prompt (Gemini if Streamlit, ChatGPT if Plotly):**\n",
    "```\n",
    "Build src/dashboard/app.py using Streamlit.\n",
    "\n",
    "Features:\n",
    "- Upload new data and trigger retraining\n",
    "- Display revenue trend (historical vs forecast)\n",
    "- Show feature importance chart\n",
    "- Show cluster segmentation visualization\n",
    "- Display model performance metrics (RMSE, MAE, R²)\n",
    "Add buttons: \"Retrain Model\", \"Refresh Forecast\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🪮 **STEP 9 — MATH & FORECAST VALIDATION (DeepSeek)**\n",
    "**Goal:** Verify your math and statistical integrity.  \n",
    "\n",
    "**Prompt for DeepSeek:**\n",
    "```\n",
    "Review my forecasting approach in model_training.py and time_series_model.py.\n",
    "Check if RMSE, MAE, and R² are implemented correctly, and whether Prophet/ARIMA\n",
    "is used properly for monthly data. Suggest improvements for statistical validity.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🖥️ **STEP 10 — LOCAL DEPLOYMENT (ChatGPT)**\n",
    "**Goal:** Run locally and deploy to IBM Watson.  \n",
    "\n",
    "**Prompt for ChatGPT:**\n",
    "```\n",
    "Provide full local deployment instructions for the FDE project.\n",
    "\n",
    "Include:\n",
    "1. Creating virtual environment\n",
    "2. Installing dependencies\n",
    "3. Running Makefile commands\n",
    "4. Launching dashboard locally\n",
    "5. Packaging for IBM Watson Studio deployment\n",
    "\n",
    "Also include sample README content for easy documentation.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ⚡ BONUS PROMPTS\n",
    "\n",
    "### 🪮 For **DeepSeek** (sanity check your results):\n",
    "> Validate the correlation between time series residuals and forecasted revenue. Are they autocorrelated? If yes, suggest model improvement.\n",
    "\n",
    "### 💡 For **Gemini** (EDA visuals):\n",
    "> Create 3 plots: revenue trend over time, region-wise average revenue, and product-category distribution. Use Matplotlib and Seaborn.\n",
    "\n",
    "---\n",
    "\n",
    "# 📂 INPUT DATA SCHEMA\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| month | string | Format YYYY-MM |\n",
    "| region | string | Region name (North/South/East/West) |\n",
    "| product_category | string | Product category (Software/Hardware/Services) |\n",
    "| line_item_description | string | Text invoice-like description |\n",
    "| revenue | float | Monthly revenue value |\n",
    "\n",
    "---\n",
    "\n",
    "# 🧠 FINAL TL;DR\n",
    "- **Claude** → Project structure + docs  \n",
    "- **Gemini** → Generate dataset + visuals + dashboard  \n",
    "- **ChatGPT (GPT-5)** → Preprocessing + clustering + modeling + retraining  \n",
    "- **DeepSeek** → Validate your math & forecasts  \n",
    "- **Copilot** → Clean up code in VS Code  \n",
    "- **Grok** → Crack a joke when you rage-debug 😅\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf54e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
